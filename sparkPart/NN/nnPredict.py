#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Date    : 2018-04-20 10:39:25
# @Author  : guanglinzhou (xdzgl812@163.com)
# @Link    : https://github.com/GuanglinZhou
# @Version : $Id$
# from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer
from pyspark.sql import SparkSession
from pyspark.ml.linalg import Vectors
from pyspark.ml.classification import MultilayerPerceptronClassificationModel
from pyspark.sql.functions import udf

if __name__ == '__main__':
    spark = SparkSession.builder.appName("generateNNPred").getOrCreate()
    sc = spark.sparkContext
    ilist = [  66526, 66527, 66531,
             66532, 66533, 66535, 66538, 66539, 66542, 66545, 66546, 66547, 66549, 66550, 66551, 66552, 66553, 66556,
             66560, 66590, 66785, 66786, 66802, 66805, 66809, 66814, 66815, 66820, 66821, 66822, 66823, 66829, 66830,
             66832, 66833, 66834, 66835, 66836, 66843, 66849, 66850, 67073, 67074, 67092, 67094, 67109, 67112, 67120,
             67123, 67125, 67126, 67130, 67133, 67142, 67143, 67147, 67148, 67149, 67363, 67382, 67383, 67384, 67399,
             67401, 67402, 67413, 67414, 67416, 67417, 67419, 67420, 67427, 67428, 67430, 67431, 67432, 67671, 67672,
             67673, 67688, 67689, 67690, 67691, 67701, 67708, 67709, 67718, 67719, 67728, 67961, 67962, 67977, 67978,
             67980, 67981, 67984, 67989, 67990, 67995, 67996, 67997, 67999, 68007, 68009, 68010, 68011, 68017, 68018,
             68019, 68251, 68267, 68268, 68269, 68270, 68274, 68279, 68284, 68285, 68286, 68287, 68288, 68301, 68307,
             68308, 68556, 68557, 68558, 68559, 68560, 68562, 68563, 68569, 68573, 68574, 68575, 68576, 68591, 68597,
             68598, 68846, 68847, 68848, 68849, 68850, 68853, 68858, 68859, 68861, 68866, 68870, 68881, 68885, 68887,
             68888, 68889, 69136, 69137, 69138, 69139, 69140, 69141, 69142, 69144, 69148, 69150, 69151, 69154, 69156,
             69169, 69170, 69171, 69172, 69177, 69425, 69426, 69427, 69429, 69432, 69433, 69434, 69438, 69442, 69443,
             69446, 69455, 69462, 69467, 69715, 69716, 69718, 69722, 69724, 69728, 69731, 69732, 69736, 69742, 69743,
             69744, 69745, 69751, 69752, 69753, 69755, 69757, 70005, 70006, 70008, 70012, 70018, 70030, 70031, 70032,
             70033, 70034, 70042, 70043, 70044, 70045, 70046, 70048, 70049, 70295, 70296, 70297, 70298, 70299, 70300,
             70302, 70303, 70309, 70317, 70318, 70319, 70320, 70324, 70333, 70334, 70336, 70566, 70585, 70586, 70587,
             70588, 70590, 70591, 70592, 70593, 70606, 70607, 70610, 70623, 70624, 70625, 70626, 70855, 70856, 70875,
             70877, 70878, 70879, 70880, 70881, 70882, 70883, 70887, 70901, 70910, 70915, 70916, 71144, 71145, 71146,
             71165, 71166, 71168, 71169, 71170, 71171, 71172, 71202, 71206, 71435, 71436, 71455, 71467, 71485, 71724,
             71744, 71745, 71746, 71747, 71757, 71758, 71771, 71772, 71775, 72012, 72013, 72014, 72015, 72036, 72037,
             72038, 72039, 72060, 72061, 72062, 72325, 72326, 72327, 72328, 72329, 72334, 72348, 72349, 72350, 72591,
             72616, 72617, 72618, 72624, 72625, 72884, 72907, 72908, 72909, 72913, 72916, 72917, 73182, 73194, 73195,
             73197, 73203, 73205, 73472, 73485, 73486, 73487, 73489, 73491, 73492, 73494, 73775, 73776, 73781, 73782,
             73783, 73784, 74061, 74062, 74065, 74066, 74070, 74071, 74072, 74073, 74091, 74351, 74352, 74353, 74354,
             74355, 74356, 74359, 74361, 74362, 74381, 74641, 74642, 74643, 74644, 74645, 74646, 74649, 74650, 74651,
             74652, 74922, 74936, 74940, 75226, 75229, 75230, 75520, 75817, 76384, 76385, 76391, 76397, 76402, 76687,
             76691, 76692, 76962, 77251, 77252, 77255, 77256, 77540, 77541, 77542, 77828, 77829, 77830, 77831, 77832,
             78118, 78119, 78122, 78409, 78410, 78411, 78412, 79862, 80152]
    for index in ilist:
        model = MultilayerPerceptronClassificationModel.load(
            'hdfs://master:9000///fcd/split/NN/serialModel/model_{}'.format(index))
        test = sc.textFile('hdfs://master:9000//fcd/split/test/397-290_testDataSplit/testData_{}.csv'.format(index))
        test = test.map(lambda line: line.split(','))
        columnName = test.take(1)[0]
        test = test.filter(lambda row: row != columnName).toDF(columnName)
        test = test.rdd.map(lambda x: (Vectors.dense(x[0:-1]), x[-1])).toDF(["features", "label"])

        labelIndexer = spark.read.format('parquet').load(
            'hdfs://master:9000//fcd/split/NN/labelIndexer/labelIndexer_{}'.format(index))
        index_secID_dict = dict(labelIndexer.rdd.map(lambda x: (str(x['index']), x['secID'])).collect())
        pred = model.transform(test)


        def func(s):
            return index_secID_dict[str(int(s))]


        func_udf = udf(func)
        pred = pred.withColumn('pred', func_udf('prediction')).select('pred')
        pred.write.csv('hdfs://master:9000//fcd/split/NN/pred/numExecutors/num10/pred_{}.csv'.format(index))
    sc.stop()





